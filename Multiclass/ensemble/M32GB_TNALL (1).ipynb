{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRA4adyjdWcn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blwR7ARVeBNY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-miIBab7lnn8",
        "outputId": "38f976e4-268a-4d72-e8b2-d3d3bb5adb61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LdwlZ485K_f"
      },
      "source": [
        "## Feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "TEXSNkUHYSl7",
        "outputId": "96891c6e-3c5d-4038-c014-8505ae1618b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      domain_name dga_family      domain  length   entropy  first_Digit_Index  \\\n",
              "0  odqzesdvd.info     nymaim   odqzesdvd       9  2.641604                  0   \n",
              "1  mcrwnxdzu.info     nymaim   mcrwnxdzu       9  3.169925                  0   \n",
              "2  poxrscvfoy.biz     nymaim  poxrscvfoy      10  3.121928                  0   \n",
              "3     dupzwi.info     nymaim      dupzwi       6  2.584963                  0   \n",
              "4     pgldibr.com     nymaim     pgldibr       7  2.807355                  0   \n",
              "\n",
              "   H_entropy  vowel_consonant_ratio  vowel_character_ratio  \\\n",
              "0   3.324863               0.444444               0.285714   \n",
              "1   3.664498               0.300000               0.214286   \n",
              "2   3.664498               0.300000               0.214286   \n",
              "3   3.277613               0.666667               0.363636   \n",
              "4   3.459432               0.250000               0.181818   \n",
              "\n",
              "   consonant_character_ratio  level_no  alexa_grams  words_grams  \n",
              "0                   0.642857         2     8.618689    10.200253  \n",
              "1                   0.714286         2     5.331953     4.442651  \n",
              "2                   0.714286         2     9.758886    11.231941  \n",
              "3                   0.545455         2     3.861893     7.928046  \n",
              "4                   0.727273         2    12.146719    20.785039  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-870f33b3-ab3f-4092-8657-65450b9136bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>domain_name</th>\n",
              "      <th>dga_family</th>\n",
              "      <th>domain</th>\n",
              "      <th>length</th>\n",
              "      <th>entropy</th>\n",
              "      <th>first_Digit_Index</th>\n",
              "      <th>H_entropy</th>\n",
              "      <th>vowel_consonant_ratio</th>\n",
              "      <th>vowel_character_ratio</th>\n",
              "      <th>consonant_character_ratio</th>\n",
              "      <th>level_no</th>\n",
              "      <th>alexa_grams</th>\n",
              "      <th>words_grams</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>odqzesdvd.info</td>\n",
              "      <td>nymaim</td>\n",
              "      <td>odqzesdvd</td>\n",
              "      <td>9</td>\n",
              "      <td>2.641604</td>\n",
              "      <td>0</td>\n",
              "      <td>3.324863</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>2</td>\n",
              "      <td>8.618689</td>\n",
              "      <td>10.200253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mcrwnxdzu.info</td>\n",
              "      <td>nymaim</td>\n",
              "      <td>mcrwnxdzu</td>\n",
              "      <td>9</td>\n",
              "      <td>3.169925</td>\n",
              "      <td>0</td>\n",
              "      <td>3.664498</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2</td>\n",
              "      <td>5.331953</td>\n",
              "      <td>4.442651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>poxrscvfoy.biz</td>\n",
              "      <td>nymaim</td>\n",
              "      <td>poxrscvfoy</td>\n",
              "      <td>10</td>\n",
              "      <td>3.121928</td>\n",
              "      <td>0</td>\n",
              "      <td>3.664498</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2</td>\n",
              "      <td>9.758886</td>\n",
              "      <td>11.231941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dupzwi.info</td>\n",
              "      <td>nymaim</td>\n",
              "      <td>dupzwi</td>\n",
              "      <td>6</td>\n",
              "      <td>2.584963</td>\n",
              "      <td>0</td>\n",
              "      <td>3.277613</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>2</td>\n",
              "      <td>3.861893</td>\n",
              "      <td>7.928046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pgldibr.com</td>\n",
              "      <td>nymaim</td>\n",
              "      <td>pgldibr</td>\n",
              "      <td>7</td>\n",
              "      <td>2.807355</td>\n",
              "      <td>0</td>\n",
              "      <td>3.459432</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>2</td>\n",
              "      <td>12.146719</td>\n",
              "      <td>20.785039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-870f33b3-ab3f-4092-8657-65450b9136bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-870f33b3-ab3f-4092-8657-65450b9136bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-870f33b3-ab3f-4092-8657-65450b9136bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "Domain_data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/MLDOMAIN_MCLS2.csv')\n",
        "Domain_data.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
        "Domain_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caPzkrCWsDXe"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Create label encoder object\n",
        "labels = LabelEncoder()\n",
        "\n",
        "# Convert continous y values to categorical\n",
        "Domain_data['family_label'] = labels.fit_transform(Domain_data['dga_family'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "0K27UolAiMld",
        "outputId": "a6dcf6ea-86fb-4a74-a083-c000a25717b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      domain_name dga_family      domain  length   entropy  first_Digit_Index  \\\n",
              "0  odqzesdvd.info     nymaim   odqzesdvd       9  2.641604                  0   \n",
              "1  mcrwnxdzu.info     nymaim   mcrwnxdzu       9  3.169925                  0   \n",
              "2  poxrscvfoy.biz     nymaim  poxrscvfoy      10  3.121928                  0   \n",
              "3     dupzwi.info     nymaim      dupzwi       6  2.584963                  0   \n",
              "4     pgldibr.com     nymaim     pgldibr       7  2.807355                  0   \n",
              "\n",
              "   H_entropy  vowel_consonant_ratio  vowel_character_ratio  \\\n",
              "0   3.324863               0.444444               0.285714   \n",
              "1   3.664498               0.300000               0.214286   \n",
              "2   3.664498               0.300000               0.214286   \n",
              "3   3.277613               0.666667               0.363636   \n",
              "4   3.459432               0.250000               0.181818   \n",
              "\n",
              "   consonant_character_ratio  level_no  alexa_grams  words_grams  family_label  \n",
              "0                   0.642857         2     8.618689    10.200253            32  \n",
              "1                   0.714286         2     5.331953     4.442651            32  \n",
              "2                   0.714286         2     9.758886    11.231941            32  \n",
              "3                   0.545455         2     3.861893     7.928046            32  \n",
              "4                   0.727273         2    12.146719    20.785039            32  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07fc74c9-dcbf-4bdc-ad88-c5c368cc54dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>domain_name</th>\n",
              "      <th>dga_family</th>\n",
              "      <th>domain</th>\n",
              "      <th>length</th>\n",
              "      <th>entropy</th>\n",
              "      <th>first_Digit_Index</th>\n",
              "      <th>H_entropy</th>\n",
              "      <th>vowel_consonant_ratio</th>\n",
              "      <th>vowel_character_ratio</th>\n",
              "      <th>consonant_character_ratio</th>\n",
              "      <th>level_no</th>\n",
              "      <th>alexa_grams</th>\n",
              "      <th>words_grams</th>\n",
              "      <th>family_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>odqzesdvd.info</td>\n",
              "      <td>nymaim</td>\n",
              "      <td>odqzesdvd</td>\n",
              "      <td>9</td>\n",
              "      <td>2.641604</td>\n",
              "      <td>0</td>\n",
              "      <td>3.324863</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>2</td>\n",
              "      <td>8.618689</td>\n",
              "      <td>10.200253</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mcrwnxdzu.info</td>\n",
              "      <td>nymaim</td>\n",
              "      <td>mcrwnxdzu</td>\n",
              "      <td>9</td>\n",
              "      <td>3.169925</td>\n",
              "      <td>0</td>\n",
              "      <td>3.664498</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2</td>\n",
              "      <td>5.331953</td>\n",
              "      <td>4.442651</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>poxrscvfoy.biz</td>\n",
              "      <td>nymaim</td>\n",
              "      <td>poxrscvfoy</td>\n",
              "      <td>10</td>\n",
              "      <td>3.121928</td>\n",
              "      <td>0</td>\n",
              "      <td>3.664498</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2</td>\n",
              "      <td>9.758886</td>\n",
              "      <td>11.231941</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dupzwi.info</td>\n",
              "      <td>nymaim</td>\n",
              "      <td>dupzwi</td>\n",
              "      <td>6</td>\n",
              "      <td>2.584963</td>\n",
              "      <td>0</td>\n",
              "      <td>3.277613</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>2</td>\n",
              "      <td>3.861893</td>\n",
              "      <td>7.928046</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pgldibr.com</td>\n",
              "      <td>nymaim</td>\n",
              "      <td>pgldibr</td>\n",
              "      <td>7</td>\n",
              "      <td>2.807355</td>\n",
              "      <td>0</td>\n",
              "      <td>3.459432</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>2</td>\n",
              "      <td>12.146719</td>\n",
              "      <td>20.785039</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07fc74c9-dcbf-4bdc-ad88-c5c368cc54dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07fc74c9-dcbf-4bdc-ad88-c5c368cc54dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07fc74c9-dcbf-4bdc-ad88-c5c368cc54dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "Domain_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3K1kDcDclM0"
      },
      "outputs": [],
      "source": [
        "grouped = Domain_data.groupby('family_label')\n",
        "Domain = grouped.filter(lambda x: x['family_label'].count() > 5.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "TbaV1rMUdYY8",
        "outputId": "86faf202-3da8-4127-bd03-b872392d63e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      domain_name dga_family      domain  length   entropy  first_Digit_Index  \\\n",
              "0  odqzesdvd.info     nymaim   odqzesdvd       9  2.641604                  0   \n",
              "1  mcrwnxdzu.info     nymaim   mcrwnxdzu       9  3.169925                  0   \n",
              "2  poxrscvfoy.biz     nymaim  poxrscvfoy      10  3.121928                  0   \n",
              "3     dupzwi.info     nymaim      dupzwi       6  2.584963                  0   \n",
              "4     pgldibr.com     nymaim     pgldibr       7  2.807355                  0   \n",
              "\n",
              "   H_entropy  vowel_consonant_ratio  vowel_character_ratio  \\\n",
              "0   3.324863               0.444444               0.285714   \n",
              "1   3.664498               0.300000               0.214286   \n",
              "2   3.664498               0.300000               0.214286   \n",
              "3   3.277613               0.666667               0.363636   \n",
              "4   3.459432               0.250000               0.181818   \n",
              "\n",
              "   consonant_character_ratio  level_no  alexa_grams  words_grams  family_label  \n",
              "0                   0.642857         2     8.618689    10.200253            32  \n",
              "1                   0.714286         2     5.331953     4.442651            32  \n",
              "2                   0.714286         2     9.758886    11.231941            32  \n",
              "3                   0.545455         2     3.861893     7.928046            32  \n",
              "4                   0.727273         2    12.146719    20.785039            32  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2adc50a-6442-4cd6-a372-b5106e6856d9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>domain_name</th>\n",
              "      <th>dga_family</th>\n",
              "      <th>domain</th>\n",
              "      <th>length</th>\n",
              "      <th>entropy</th>\n",
              "      <th>first_Digit_Index</th>\n",
              "      <th>H_entropy</th>\n",
              "      <th>vowel_consonant_ratio</th>\n",
              "      <th>vowel_character_ratio</th>\n",
              "      <th>consonant_character_ratio</th>\n",
              "      <th>level_no</th>\n",
              "      <th>alexa_grams</th>\n",
              "      <th>words_grams</th>\n",
              "      <th>family_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>odqzesdvd.info</td>\n",
              "      <td>nymaim</td>\n",
              "      <td>odqzesdvd</td>\n",
              "      <td>9</td>\n",
              "      <td>2.641604</td>\n",
              "      <td>0</td>\n",
              "      <td>3.324863</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>2</td>\n",
              "      <td>8.618689</td>\n",
              "      <td>10.200253</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mcrwnxdzu.info</td>\n",
              "      <td>nymaim</td>\n",
              "      <td>mcrwnxdzu</td>\n",
              "      <td>9</td>\n",
              "      <td>3.169925</td>\n",
              "      <td>0</td>\n",
              "      <td>3.664498</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2</td>\n",
              "      <td>5.331953</td>\n",
              "      <td>4.442651</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>poxrscvfoy.biz</td>\n",
              "      <td>nymaim</td>\n",
              "      <td>poxrscvfoy</td>\n",
              "      <td>10</td>\n",
              "      <td>3.121928</td>\n",
              "      <td>0</td>\n",
              "      <td>3.664498</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>2</td>\n",
              "      <td>9.758886</td>\n",
              "      <td>11.231941</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dupzwi.info</td>\n",
              "      <td>nymaim</td>\n",
              "      <td>dupzwi</td>\n",
              "      <td>6</td>\n",
              "      <td>2.584963</td>\n",
              "      <td>0</td>\n",
              "      <td>3.277613</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>2</td>\n",
              "      <td>3.861893</td>\n",
              "      <td>7.928046</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pgldibr.com</td>\n",
              "      <td>nymaim</td>\n",
              "      <td>pgldibr</td>\n",
              "      <td>7</td>\n",
              "      <td>2.807355</td>\n",
              "      <td>0</td>\n",
              "      <td>3.459432</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>2</td>\n",
              "      <td>12.146719</td>\n",
              "      <td>20.785039</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2adc50a-6442-4cd6-a372-b5106e6856d9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d2adc50a-6442-4cd6-a372-b5106e6856d9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d2adc50a-6442-4cd6-a372-b5106e6856d9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "Domain.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ww2FnURIde-i"
      },
      "outputs": [],
      "source": [
        "X= Domain.drop([\"dga_family\", \"domain_name\", \"domain\",\"family_label\"], axis=1)\n",
        "y = Domain[\"family_label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9COoOB4dXOC",
        "outputId": "1655b8b3-ec59-4316-8599-28204b8d0fb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "family_label\n",
              "0         27\n",
              "1         16\n",
              "2        104\n",
              "3     469896\n",
              "4       1000\n",
              "7       1000\n",
              "8        492\n",
              "9         11\n",
              "10      1000\n",
              "11       736\n",
              "12      1000\n",
              "13    500540\n",
              "14       492\n",
              "15       247\n",
              "16     29999\n",
              "17       298\n",
              "18       299\n",
              "19     12000\n",
              "20       100\n",
              "21       124\n",
              "22    613032\n",
              "23      1158\n",
              "25       908\n",
              "27      8560\n",
              "28     10047\n",
              "29      2708\n",
              "30      8190\n",
              "31      5274\n",
              "32       333\n",
              "33        40\n",
              "34       168\n",
              "35       100\n",
              "36     44675\n",
              "37       800\n",
              "38       199\n",
              "39      2000\n",
              "40     19532\n",
              "41     11160\n",
              "42    179995\n",
              "43      2545\n",
              "44      6015\n",
              "45     28121\n",
              "46      2298\n",
              "47      4256\n",
              "48       193\n",
              "49     93707\n",
              "50        32\n",
              "51        20\n",
              "52       510\n",
              "53       842\n",
              "54       100\n",
              "55      9733\n",
              "Name: family_label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "grouped=y.groupby(y)\n",
        "grouped.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ePogM6szcHFb",
        "outputId": "907b12bb-82fb-450a-f688-0634c80ecc7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class=32, n=333 (0.016%)\n",
            "Class=19, n=12000 (0.578%)\n",
            "Class=23, n=1158 (0.056%)\n",
            "Class=47, n=4256 (0.205%)\n",
            "Class=8, n=492 (0.024%)\n",
            "Class=38, n=199 (0.010%)\n",
            "Class=37, n=800 (0.039%)\n",
            "Class=2, n=104 (0.005%)\n",
            "Class=39, n=2000 (0.096%)\n",
            "Class=30, n=8190 (0.394%)\n",
            "Class=10, n=1000 (0.048%)\n",
            "Class=35, n=100 (0.005%)\n",
            "Class=41, n=11160 (0.537%)\n",
            "Class=27, n=8560 (0.412%)\n",
            "Class=46, n=2298 (0.111%)\n",
            "Class=54, n=100 (0.005%)\n",
            "Class=51, n=20 (0.001%)\n",
            "Class=7, n=1000 (0.048%)\n",
            "Class=55, n=9733 (0.469%)\n",
            "Class=13, n=500540 (24.103%)\n",
            "Class=25, n=908 (0.044%)\n",
            "Class=34, n=168 (0.008%)\n",
            "Class=50, n=32 (0.002%)\n",
            "Class=12, n=1000 (0.048%)\n",
            "Class=28, n=10047 (0.484%)\n",
            "Class=4, n=1000 (0.048%)\n",
            "Class=1, n=16 (0.001%)\n",
            "Class=16, n=29999 (1.445%)\n",
            "Class=9, n=11 (0.001%)\n",
            "Class=0, n=27 (0.001%)\n",
            "Class=52, n=510 (0.025%)\n",
            "Class=17, n=298 (0.014%)\n",
            "Class=18, n=299 (0.014%)\n",
            "Class=3, n=469896 (22.628%)\n",
            "Class=49, n=93707 (4.512%)\n",
            "Class=40, n=19532 (0.941%)\n",
            "Class=45, n=28121 (1.354%)\n",
            "Class=11, n=736 (0.035%)\n",
            "Class=48, n=193 (0.009%)\n",
            "Class=53, n=842 (0.041%)\n",
            "Class=42, n=179995 (8.668%)\n",
            "Class=20, n=100 (0.005%)\n",
            "Class=36, n=44675 (2.151%)\n",
            "Class=43, n=2545 (0.123%)\n",
            "Class=33, n=40 (0.002%)\n",
            "Class=15, n=247 (0.012%)\n",
            "Class=44, n=6015 (0.290%)\n",
            "Class=14, n=492 (0.024%)\n",
            "Class=31, n=5274 (0.254%)\n",
            "Class=29, n=2708 (0.130%)\n",
            "Class=21, n=124 (0.006%)\n",
            "Class=22, n=613032 (29.520%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from matplotlib import pyplot\n",
        "from collections import Counter\n",
        "counter = Counter(y)\n",
        "for k,v in counter.items():\n",
        "\tper = v / len(y) * 100\n",
        "\tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
        "# plot the distribution\n",
        "pyplot.bar(counter.keys(), counter.values())\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw04szrQsHRr"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8,  random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_cyhEig6k-B7",
        "outputId": "09f0d938-70b0-475d-edde-0c434307c2eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class=13, n=400469 (24.106%)\n",
            "Class=3, n=375759 (22.618%)\n",
            "Class=22, n=490589 (29.530%)\n",
            "Class=36, n=35841 (2.157%)\n",
            "Class=47, n=3430 (0.206%)\n",
            "Class=16, n=24017 (1.446%)\n",
            "Class=49, n=74975 (4.513%)\n",
            "Class=27, n=6861 (0.413%)\n",
            "Class=42, n=143993 (8.667%)\n",
            "Class=19, n=9586 (0.577%)\n",
            "Class=44, n=4793 (0.289%)\n",
            "Class=28, n=7980 (0.480%)\n",
            "Class=55, n=7803 (0.470%)\n",
            "Class=31, n=4178 (0.251%)\n",
            "Class=40, n=15574 (0.937%)\n",
            "Class=41, n=8963 (0.540%)\n",
            "Class=45, n=22430 (1.350%)\n",
            "Class=53, n=677 (0.041%)\n",
            "Class=46, n=1825 (0.110%)\n",
            "Class=30, n=6547 (0.394%)\n",
            "Class=29, n=2168 (0.130%)\n",
            "Class=37, n=650 (0.039%)\n",
            "Class=15, n=203 (0.012%)\n",
            "Class=43, n=2061 (0.124%)\n",
            "Class=8, n=403 (0.024%)\n",
            "Class=17, n=247 (0.015%)\n",
            "Class=18, n=236 (0.014%)\n",
            "Class=35, n=83 (0.005%)\n",
            "Class=25, n=718 (0.043%)\n",
            "Class=10, n=786 (0.047%)\n",
            "Class=4, n=790 (0.048%)\n",
            "Class=14, n=398 (0.024%)\n",
            "Class=39, n=1625 (0.098%)\n",
            "Class=12, n=782 (0.047%)\n",
            "Class=11, n=585 (0.035%)\n",
            "Class=32, n=264 (0.016%)\n",
            "Class=7, n=803 (0.048%)\n",
            "Class=52, n=401 (0.024%)\n",
            "Class=34, n=136 (0.008%)\n",
            "Class=48, n=154 (0.009%)\n",
            "Class=33, n=29 (0.002%)\n",
            "Class=23, n=917 (0.055%)\n",
            "Class=38, n=164 (0.010%)\n",
            "Class=50, n=26 (0.002%)\n",
            "Class=2, n=76 (0.005%)\n",
            "Class=21, n=95 (0.006%)\n",
            "Class=9, n=10 (0.001%)\n",
            "Class=20, n=78 (0.005%)\n",
            "Class=54, n=85 (0.005%)\n",
            "Class=1, n=11 (0.001%)\n",
            "Class=51, n=14 (0.001%)\n",
            "Class=0, n=17 (0.001%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from matplotlib import pyplot\n",
        "from collections import Counter\n",
        "counter = Counter(y_train)\n",
        "for k,v in counter.items():\n",
        "\tper = v / len(y_train) * 100\n",
        "\tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
        "# plot the distribution\n",
        "pyplot.bar(counter.keys(), counter.values())\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99iXworaltQT",
        "outputId": "e9d1a4c4-dd66-41e6-f067-fea79b0a16e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "family_label\n",
              "0         17\n",
              "1         11\n",
              "2         76\n",
              "3     375759\n",
              "4        790\n",
              "7        803\n",
              "8        403\n",
              "9         10\n",
              "10       786\n",
              "11       585\n",
              "12       782\n",
              "13    400469\n",
              "14       398\n",
              "15       203\n",
              "16     24017\n",
              "17       247\n",
              "18       236\n",
              "19      9586\n",
              "20        78\n",
              "21        95\n",
              "22    490589\n",
              "23       917\n",
              "25       718\n",
              "27      6861\n",
              "28      7980\n",
              "29      2168\n",
              "30      6547\n",
              "31      4178\n",
              "32       264\n",
              "33        29\n",
              "34       136\n",
              "35        83\n",
              "36     35841\n",
              "37       650\n",
              "38       164\n",
              "39      1625\n",
              "40     15574\n",
              "41      8963\n",
              "42    143993\n",
              "43      2061\n",
              "44      4793\n",
              "45     22430\n",
              "46      1825\n",
              "47      3430\n",
              "48       154\n",
              "49     74975\n",
              "50        26\n",
              "51        14\n",
              "52       401\n",
              "53       677\n",
              "54        85\n",
              "55      7803\n",
              "Name: family_label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "grouped=y_train.groupby(y_train)\n",
        "grouped.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5pphpq2G75l"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "strategy = {0:16613,1:16613,2:16613, 4:16613, 7:16613, 8:16613, 9:16613, 10:16613, 11:16613, 12:16613, 14:16613, 15:16613, 18:16613, 17:16613,19:16613, 20:16613,21:16613,23:16613,25:16613,27:16613,28:16613,29:16613,30:16613,31:16613,32:16613,33:16613,34:16613,35:16613,37:16613,38:16613,39:16613,41:16613,43:16613,44:16613,46:16613,47:16613, 48:16613,50:16613,51:16613, 52:16613, 53:16613, 54:16613,55:16613}\n",
        "#for i in minmum_classes:\n",
        "ovrsmt = RandomOverSampler(sampling_strategy=strategy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCJxx09rJaIs"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "udrsmt = RandomUnderSampler(sampling_strategy={42:143527,22:203528,13:193527,3:193529})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyWrOJPiJ5uQ"
      },
      "outputs": [],
      "source": [
        "from imblearn.pipeline import Pipeline\n",
        "steps = [('o', ovrsmt), ('u', udrsmt)]\n",
        "pipeline = Pipeline(steps=steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XykMUS8uJ8VP"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = pipeline.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQJk8KKSmI6T",
        "outputId": "b382a72c-17f6-46cd-c363-c63ceeb309c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "family_label\n",
              "0      16613\n",
              "1      16613\n",
              "2      16613\n",
              "3     193529\n",
              "4      16613\n",
              "7      16613\n",
              "8      16613\n",
              "9      16613\n",
              "10     16613\n",
              "11     16613\n",
              "12     16613\n",
              "13    193527\n",
              "14     16613\n",
              "15     16613\n",
              "16     24017\n",
              "17     16613\n",
              "18     16613\n",
              "19     16613\n",
              "20     16613\n",
              "21     16613\n",
              "22    203528\n",
              "23     16613\n",
              "25     16613\n",
              "27     16613\n",
              "28     16613\n",
              "29     16613\n",
              "30     16613\n",
              "31     16613\n",
              "32     16613\n",
              "33     16613\n",
              "34     16613\n",
              "35     16613\n",
              "36     35841\n",
              "37     16613\n",
              "38     16613\n",
              "39     16613\n",
              "40     15574\n",
              "41     16613\n",
              "42    143527\n",
              "43     16613\n",
              "44     16613\n",
              "45     22430\n",
              "46     16613\n",
              "47     16613\n",
              "48     16613\n",
              "49     74975\n",
              "50     16613\n",
              "51     16613\n",
              "52     16613\n",
              "53     16613\n",
              "54     16613\n",
              "55     16613\n",
              "Name: family_label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "grouped=y_train.groupby(y_train)\n",
        "grouped.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cJx7R8gTcKXT",
        "outputId": "9b76a380-f18f-4acb-a261-3939d4fed61b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class=0, n=16613 (1.025%)\n",
            "Class=1, n=16613 (1.025%)\n",
            "Class=2, n=16613 (1.025%)\n",
            "Class=3, n=193529 (11.937%)\n",
            "Class=4, n=16613 (1.025%)\n",
            "Class=7, n=16613 (1.025%)\n",
            "Class=8, n=16613 (1.025%)\n",
            "Class=9, n=16613 (1.025%)\n",
            "Class=10, n=16613 (1.025%)\n",
            "Class=11, n=16613 (1.025%)\n",
            "Class=12, n=16613 (1.025%)\n",
            "Class=13, n=193527 (11.936%)\n",
            "Class=14, n=16613 (1.025%)\n",
            "Class=15, n=16613 (1.025%)\n",
            "Class=16, n=24017 (1.481%)\n",
            "Class=17, n=16613 (1.025%)\n",
            "Class=18, n=16613 (1.025%)\n",
            "Class=19, n=16613 (1.025%)\n",
            "Class=20, n=16613 (1.025%)\n",
            "Class=21, n=16613 (1.025%)\n",
            "Class=22, n=203528 (12.553%)\n",
            "Class=23, n=16613 (1.025%)\n",
            "Class=25, n=16613 (1.025%)\n",
            "Class=27, n=16613 (1.025%)\n",
            "Class=28, n=16613 (1.025%)\n",
            "Class=29, n=16613 (1.025%)\n",
            "Class=30, n=16613 (1.025%)\n",
            "Class=31, n=16613 (1.025%)\n",
            "Class=32, n=16613 (1.025%)\n",
            "Class=33, n=16613 (1.025%)\n",
            "Class=34, n=16613 (1.025%)\n",
            "Class=35, n=16613 (1.025%)\n",
            "Class=36, n=35841 (2.211%)\n",
            "Class=37, n=16613 (1.025%)\n",
            "Class=38, n=16613 (1.025%)\n",
            "Class=39, n=16613 (1.025%)\n",
            "Class=40, n=15574 (0.961%)\n",
            "Class=41, n=16613 (1.025%)\n",
            "Class=42, n=143527 (8.853%)\n",
            "Class=43, n=16613 (1.025%)\n",
            "Class=44, n=16613 (1.025%)\n",
            "Class=45, n=22430 (1.383%)\n",
            "Class=46, n=16613 (1.025%)\n",
            "Class=47, n=16613 (1.025%)\n",
            "Class=48, n=16613 (1.025%)\n",
            "Class=49, n=74975 (4.624%)\n",
            "Class=50, n=16613 (1.025%)\n",
            "Class=51, n=16613 (1.025%)\n",
            "Class=52, n=16613 (1.025%)\n",
            "Class=53, n=16613 (1.025%)\n",
            "Class=54, n=16613 (1.025%)\n",
            "Class=55, n=16613 (1.025%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from matplotlib import pyplot\n",
        "from collections import Counter\n",
        "counter = Counter(y_train)\n",
        "for k,v in counter.items():\n",
        "\tper = v / len(y_train) * 100\n",
        "\tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
        "# plot the distribution\n",
        "pyplot.bar(counter.keys(), counter.values())\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qQL0V9OP8qk"
      },
      "source": [
        "## Ensembling "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7469Dufstn5"
      },
      "outputs": [],
      "source": [
        "#  ML Algorithms used \n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn import model_selection\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import precision_score, accuracy_score,classification_report\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVCBZ8m3s2Bz",
        "outputId": "6fef40d3-5171-424c-c470-bffd4f2b209c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X train size:  (1621307, 10)\n",
            "y train size:  (1621307,)\n",
            "X test size:  (415327, 10)\n",
            "y test size:  (415327,)\n"
          ]
        }
      ],
      "source": [
        "print('X train size: ', X_train.shape)\n",
        "print('y train size: ', y_train.shape)\n",
        "print('X test size: ', X_test.shape)\n",
        "print('y test size: ', y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ciAuVvNeYL5"
      },
      "source": [
        "### tuning RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTX-NqeIeaGn"
      },
      "outputs": [],
      "source": [
        "from sklearn.experimental import enable_halving_search_cv  \n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfclf = RandomForestClassifier()\n",
        "rfparam = {'n_estimators': [50,100,150,200],\n",
        "    'max_depth' : [10, 20, 50,100]                                                                                                                  \n",
        "           }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UV8PTQnQec84"
      },
      "outputs": [],
      "source": [
        "# train across 10 folds, that's a total of (12+6)*5=90 rounds of training \n",
        "grid_forest_clf = HalvingGridSearchCV(rfclf, rfparam, scoring='accuracy')\n",
        "grid_forest_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2p4lV_Y4_iI",
        "outputId": "4055e223-803e-4b12-eb4b-3129c6dc724c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best: 0.977290 using {'max_depth': 100, 'n_estimators': 200}\n",
            "0.778275 (0.002584) with: {'max_depth': 10, 'n_estimators': 50}\n",
            "0.779174 (0.002809) with: {'max_depth': 10, 'n_estimators': 100}\n",
            "0.780007 (0.002239) with: {'max_depth': 10, 'n_estimators': 150}\n",
            "0.780723 (0.002052) with: {'max_depth': 10, 'n_estimators': 200}\n",
            "0.923316 (0.001156) with: {'max_depth': 20, 'n_estimators': 50}\n",
            "0.924432 (0.000673) with: {'max_depth': 20, 'n_estimators': 100}\n",
            "0.925059 (0.000308) with: {'max_depth': 20, 'n_estimators': 150}\n",
            "0.925004 (0.000568) with: {'max_depth': 20, 'n_estimators': 200}\n",
            "0.934874 (0.001046) with: {'max_depth': 50, 'n_estimators': 50}\n",
            "0.935529 (0.000909) with: {'max_depth': 50, 'n_estimators': 100}\n",
            "0.936023 (0.001219) with: {'max_depth': 50, 'n_estimators': 150}\n",
            "0.935845 (0.001034) with: {'max_depth': 50, 'n_estimators': 200}\n",
            "0.934518 (0.000750) with: {'max_depth': 100, 'n_estimators': 50}\n",
            "0.935495 (0.001002) with: {'max_depth': 100, 'n_estimators': 100}\n",
            "0.936034 (0.001062) with: {'max_depth': 100, 'n_estimators': 150}\n",
            "0.936056 (0.001056) with: {'max_depth': 100, 'n_estimators': 200}\n",
            "0.962493 (0.001377) with: {'max_depth': 100, 'n_estimators': 100}\n",
            "0.962493 (0.001441) with: {'max_depth': 50, 'n_estimators': 100}\n",
            "0.962580 (0.001487) with: {'max_depth': 50, 'n_estimators': 200}\n",
            "0.962465 (0.001432) with: {'max_depth': 50, 'n_estimators': 150}\n",
            "0.962597 (0.001435) with: {'max_depth': 100, 'n_estimators': 150}\n",
            "0.962597 (0.001356) with: {'max_depth': 100, 'n_estimators': 200}\n",
            "0.977290 (0.001856) with: {'max_depth': 100, 'n_estimators': 200}\n",
            "0.977265 (0.001869) with: {'max_depth': 100, 'n_estimators': 150}\n"
          ]
        }
      ],
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_forest_clf.best_score_, grid_forest_clf.best_params_))\n",
        "means = grid_forest_clf.cv_results_['mean_test_score']\n",
        "stds = grid_forest_clf.cv_results_['std_test_score']\n",
        "params = grid_forest_clf.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01Vq9TOFdrKI"
      },
      "outputs": [],
      "source": [
        "rfclf = RandomForestClassifier(max_depth = 100, n_estimators= 200).fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnFkCw9rd7bf",
        "outputId": "359ed650-1eb6-4d30-92cc-9c5bf8967e2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.60      0.71        10\n",
            "           1       0.67      0.80      0.73         5\n",
            "           2       0.85      1.00      0.92        28\n",
            "           3       0.98      0.99      0.99     94137\n",
            "           4       0.16      0.02      0.03       210\n",
            "           7       0.93      0.97      0.95       197\n",
            "           8       0.04      0.03      0.04        89\n",
            "           9       0.00      0.00      0.00         1\n",
            "          10       0.29      0.14      0.19       214\n",
            "          11       0.06      0.03      0.04       151\n",
            "          12       1.00      1.00      1.00       218\n",
            "          13       1.00      1.00      1.00    100071\n",
            "          14       0.92      0.96      0.94        94\n",
            "          15       0.31      0.20      0.25        44\n",
            "          16       0.90      0.94      0.92      5982\n",
            "          17       0.00      0.00      0.00        51\n",
            "          18       0.07      0.05      0.06        63\n",
            "          19       0.99      0.99      0.99      2414\n",
            "          20       0.84      0.73      0.78        22\n",
            "          21       0.93      0.48      0.64        29\n",
            "          22       0.98      0.96      0.97    122443\n",
            "          23       0.12      0.05      0.07       241\n",
            "          25       0.18      0.08      0.11       190\n",
            "          27       0.59      0.67      0.63      1699\n",
            "          28       0.82      0.91      0.86      2067\n",
            "          29       0.53      0.58      0.55       540\n",
            "          30       0.57      0.42      0.49      1643\n",
            "          31       0.79      0.78      0.78      1096\n",
            "          32       0.02      0.01      0.02        69\n",
            "          33       0.71      0.45      0.56        11\n",
            "          34       0.52      0.38      0.44        32\n",
            "          35       0.00      0.00      0.00        17\n",
            "          36       0.79      0.81      0.80      8834\n",
            "          37       0.13      0.11      0.12       150\n",
            "          38       0.00      0.00      0.00        35\n",
            "          39       0.72      0.81      0.76       375\n",
            "          40       0.58      0.44      0.50      3958\n",
            "          41       0.76      0.87      0.81      2197\n",
            "          42       1.00      0.99      0.99     36002\n",
            "          43       0.59      0.63      0.61       484\n",
            "          44       0.86      0.82      0.84      1222\n",
            "          45       0.80      0.85      0.82      5691\n",
            "          46       0.25      0.18      0.21       473\n",
            "          47       0.97      0.99      0.98       826\n",
            "          48       0.05      0.03      0.03        39\n",
            "          49       0.96      0.99      0.97     18732\n",
            "          50       0.60      0.50      0.55         6\n",
            "          51       0.75      1.00      0.86         6\n",
            "          52       0.93      0.95      0.94       109\n",
            "          53       0.03      0.02      0.02       165\n",
            "          54       0.29      0.13      0.18        15\n",
            "          55       0.55      0.77      0.64      1930\n",
            "\n",
            "    accuracy                           0.96    415327\n",
            "   macro avg       0.56      0.54      0.54    415327\n",
            "weighted avg       0.96      0.96      0.96    415327\n",
            "\n"
          ]
        }
      ],
      "source": [
        "hhhhyyuu   om sklearn.metrics import plot_confusion_matrix,accuracy_score,classification_report\n",
        "RFpred = rfclf.predict(X_test)\n",
        "print(classification_report(y_test,RFpred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXrbO-nSDv5z"
      },
      "outputs": [],
      "source": [
        "print('accuracy on the train set: ', accuracy_score(rfclf.predict(X_train), y_train))\n",
        "print('accuracy on the test set: ', accuracy_score(y_test, RFpred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHsVTpAhDv50"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pprd = rfclf.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFotE7fzDv50",
        "outputId": "3fb9e6c5-7026-4494-d07f-6de8eb1d6f0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9543725379511858\n"
          ]
        }
      ],
      "source": [
        "auc = metrics.roc_auc_score(y_test, pprd, multi_class='ovo', average='weighted')\n",
        "print(auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8dwjp89Dv51"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "# save the model to disk\n",
        "filename = '/content/drive/My Drive/Colab Notebooks/MCL_RFmodel_m_TN.sav'\n",
        "pickle.dump(rfclf, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sismJcs3JFlN"
      },
      "source": [
        "### tuning BDT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Gi2ZUt3cZ8w"
      },
      "outputs": [],
      "source": [
        "# explicitly require this experimental feature\n",
        "from sklearn.experimental import enable_halving_search_cv \n",
        "\n",
        "# now import normally from model_selection\n",
        "from sklearn.model_selection import HalvingGridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QU1bsw2MvRCp",
        "outputId": "258c386c-bf5e-4589-8e68-ae3f2fe2fe1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
              "                                         max_features=0.5, n_estimators=100),\n",
              "             param_grid={'base_estimator__max_depth': [10, 30, 50],\n",
              "                         'max_samples': [0.05, 0.2, 0.5]})"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'base_estimator__max_depth' : [10, 30, 50],\n",
        "    'max_samples' : [0.05, 0.2, 0.5]\n",
        "}\n",
        "\n",
        "clf = GridSearchCV(BaggingClassifier(DecisionTreeClassifier(),\n",
        "                                     n_estimators = 100, max_features = 0.5),\n",
        "                   param_grid)\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYyW1BJI1SA3",
        "outputId": "dc5de113-fbaf-4a71-af66-4167fb4b3c9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best: 0.971591 using {'base_estimator__max_depth': 50, 'max_samples': 0.5}\n",
            "0.770534 (0.002180) with: {'base_estimator__max_depth': 10, 'max_samples': 0.05}\n",
            "0.773037 (0.002040) with: {'base_estimator__max_depth': 10, 'max_samples': 0.2}\n",
            "0.773005 (0.001110) with: {'base_estimator__max_depth': 10, 'max_samples': 0.5}\n",
            "0.936437 (0.001218) with: {'base_estimator__max_depth': 30, 'max_samples': 0.05}\n",
            "0.962557 (0.001441) with: {'base_estimator__max_depth': 30, 'max_samples': 0.2}\n",
            "0.971049 (0.001879) with: {'base_estimator__max_depth': 30, 'max_samples': 0.5}\n",
            "0.936082 (0.002337) with: {'base_estimator__max_depth': 50, 'max_samples': 0.05}\n",
            "0.963074 (0.001324) with: {'base_estimator__max_depth': 50, 'max_samples': 0.2}\n",
            "0.971591 (0.001708) with: {'base_estimator__max_depth': 50, 'max_samples': 0.5}\n"
          ]
        }
      ],
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
        "means = clf.cv_results_['mean_test_score']\n",
        "stds = clf.cv_results_['std_test_score']\n",
        "params = clf.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8iHQivZKa_b",
        "outputId": "f3d1aa91-74e3-4669-b980-210a58e50a1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.90      0.78        10\n",
            "           1       0.71      1.00      0.83         5\n",
            "           2       0.75      0.96      0.84        28\n",
            "           3       0.97      0.98      0.98     94137\n",
            "           4       0.43      0.01      0.03       210\n",
            "           7       0.92      0.97      0.94       197\n",
            "           8       0.09      0.07      0.08        89\n",
            "           9       0.00      0.00      0.00         1\n",
            "          10       0.24      0.12      0.16       214\n",
            "          11       0.05      0.02      0.03       151\n",
            "          12       0.99      1.00      0.99       218\n",
            "          13       1.00      1.00      1.00    100071\n",
            "          14       0.88      0.98      0.93        94\n",
            "          15       0.23      0.25      0.24        44\n",
            "          16       0.91      0.92      0.92      5982\n",
            "          17       0.07      0.10      0.08        51\n",
            "          18       0.10      0.14      0.12        63\n",
            "          19       0.99      0.99      0.99      2414\n",
            "          20       0.93      0.59      0.72        22\n",
            "          21       1.00      0.62      0.77        29\n",
            "          22       0.97      0.96      0.96    122443\n",
            "          23       0.15      0.04      0.06       241\n",
            "          25       0.27      0.08      0.12       190\n",
            "          27       0.66      0.77      0.71      1699\n",
            "          28       0.79      0.91      0.85      2067\n",
            "          29       0.49      0.75      0.59       540\n",
            "          30       0.67      0.34      0.45      1643\n",
            "          31       0.89      0.73      0.80      1096\n",
            "          32       0.02      0.01      0.02        69\n",
            "          33       0.75      0.27      0.40        11\n",
            "          34       0.78      0.22      0.34        32\n",
            "          35       0.00      0.00      0.00        17\n",
            "          36       0.82      0.77      0.79      8834\n",
            "          37       0.09      0.05      0.06       150\n",
            "          38       0.00      0.00      0.00        35\n",
            "          39       0.69      0.93      0.80       375\n",
            "          40       0.67      0.32      0.43      3958\n",
            "          41       0.76      0.89      0.82      2197\n",
            "          42       0.99      1.00      0.99     36002\n",
            "          43       0.50      0.69      0.58       484\n",
            "          44       0.91      0.78      0.84      1222\n",
            "          45       0.82      0.80      0.81      5691\n",
            "          46       0.35      0.09      0.15       473\n",
            "          47       0.97      0.99      0.98       826\n",
            "          48       0.05      0.03      0.03        39\n",
            "          49       0.95      0.99      0.97     18732\n",
            "          50       0.60      0.50      0.55         6\n",
            "          51       1.00      1.00      1.00         6\n",
            "          52       0.91      0.95      0.93       109\n",
            "          53       0.06      0.04      0.05       165\n",
            "          54       0.27      0.20      0.23        15\n",
            "          55       0.52      0.89      0.66      1930\n",
            "\n",
            "    accuracy                           0.96    415327\n",
            "   macro avg       0.58      0.55      0.55    415327\n",
            "weighted avg       0.95      0.96      0.95    415327\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "bdtpred = clf.predict(X_test)\n",
        "print(classification_report(y_test,bdtpred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpvLrwj2mo2a"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pprd = clf.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "615bZ7Exmo2q",
        "outputId": "d3ddc9da-7264-40eb-826a-8fb3ae3caaec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9859281413112434\n"
          ]
        }
      ],
      "source": [
        "auc = metrics.roc_auc_score(y_test, pprd, multi_class='ovo', average='weighted')\n",
        "print(auc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yahE73i7lPY"
      },
      "source": [
        "### tuning VT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Xwkdz5D7rNI",
        "outputId": "e5d97669-e57d-4974-f113-94704992ed9e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "\n",
        "# define the base models\n",
        "estimators = []\n",
        "model1 = LogisticRegression()\n",
        "estimators.append(('lr', model1))\n",
        "model2 = DecisionTreeClassifier()\n",
        "estimators.append(('dt', model2))\n",
        "model4 = GaussianNB()\n",
        "estimators.append(('nb', model4))\n",
        "\n",
        "\n",
        "# create the ensemble model\n",
        "VTensemble = VotingClassifier(estimators,voting='soft')\n",
        "\n",
        "params = {'dt__criterion': ['gini','entropy'],\n",
        "          'dt__max_depth':[10,20],\n",
        "      'lr__C':[0.01,0.1,0.5,1],\n",
        "      }\n",
        "\n",
        "grid=HalvingGridSearchCV(VTensemble, params).fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfqQgXvAxutD",
        "outputId": "0643b6e8-3f90-441c-c737-980d51454ba7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best: 0.873703 using {'dt__criterion': 'entropy', 'dt__max_depth': 20, 'lr__C': 1}\n",
            "0.726982 (0.002106) with: {'dt__criterion': 'gini', 'dt__max_depth': 10, 'lr__C': 0.01}\n",
            "0.727054 (0.002601) with: {'dt__criterion': 'gini', 'dt__max_depth': 10, 'lr__C': 0.1}\n",
            "0.726177 (0.003287) with: {'dt__criterion': 'gini', 'dt__max_depth': 10, 'lr__C': 0.5}\n",
            "0.726277 (0.002796) with: {'dt__criterion': 'gini', 'dt__max_depth': 10, 'lr__C': 1}\n",
            "0.812004 (0.003553) with: {'dt__criterion': 'gini', 'dt__max_depth': 20, 'lr__C': 0.01}\n",
            "0.809972 (0.003382) with: {'dt__criterion': 'gini', 'dt__max_depth': 20, 'lr__C': 0.1}\n",
            "0.808568 (0.002266) with: {'dt__criterion': 'gini', 'dt__max_depth': 20, 'lr__C': 0.5}\n",
            "0.809117 (0.002936) with: {'dt__criterion': 'gini', 'dt__max_depth': 20, 'lr__C': 1}\n",
            "0.731090 (0.002484) with: {'dt__criterion': 'entropy', 'dt__max_depth': 10, 'lr__C': 0.01}\n",
            "0.730246 (0.002906) with: {'dt__criterion': 'entropy', 'dt__max_depth': 10, 'lr__C': 0.1}\n",
            "0.729264 (0.002299) with: {'dt__criterion': 'entropy', 'dt__max_depth': 10, 'lr__C': 0.5}\n",
            "0.729680 (0.001991) with: {'dt__criterion': 'entropy', 'dt__max_depth': 10, 'lr__C': 1}\n",
            "0.850957 (0.003651) with: {'dt__criterion': 'entropy', 'dt__max_depth': 20, 'lr__C': 0.01}\n",
            "0.848864 (0.002512) with: {'dt__criterion': 'entropy', 'dt__max_depth': 20, 'lr__C': 0.1}\n",
            "0.847104 (0.002951) with: {'dt__criterion': 'entropy', 'dt__max_depth': 20, 'lr__C': 0.5}\n",
            "0.848186 (0.002091) with: {'dt__criterion': 'entropy', 'dt__max_depth': 20, 'lr__C': 1}\n",
            "0.821944 (0.004503) with: {'dt__criterion': 'gini', 'dt__max_depth': 20, 'lr__C': 0.1}\n",
            "0.823463 (0.000779) with: {'dt__criterion': 'gini', 'dt__max_depth': 20, 'lr__C': 0.01}\n",
            "0.864172 (0.002234) with: {'dt__criterion': 'entropy', 'dt__max_depth': 20, 'lr__C': 0.5}\n",
            "0.865472 (0.003118) with: {'dt__criterion': 'entropy', 'dt__max_depth': 20, 'lr__C': 1}\n",
            "0.862910 (0.003964) with: {'dt__criterion': 'entropy', 'dt__max_depth': 20, 'lr__C': 0.1}\n",
            "0.864897 (0.001602) with: {'dt__criterion': 'entropy', 'dt__max_depth': 20, 'lr__C': 0.01}\n",
            "0.872923 (0.003359) with: {'dt__criterion': 'entropy', 'dt__max_depth': 20, 'lr__C': 0.01}\n",
            "0.873703 (0.003089) with: {'dt__criterion': 'entropy', 'dt__max_depth': 20, 'lr__C': 1}\n"
          ]
        }
      ],
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
        "means = grid.cv_results_['mean_test_score']\n",
        "stds = grid.cv_results_['std_test_score']\n",
        "params = grid.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        " print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd08TVmG8rTu",
        "outputId": "9034889d-db47-4986-cd31-5504bcea5f32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.05      0.80      0.10        10\n",
            "           1       0.19      0.60      0.29         5\n",
            "           2       0.79      0.79      0.79        28\n",
            "           3       0.95      0.96      0.96     94137\n",
            "           4       0.02      0.06      0.03       210\n",
            "           7       0.93      0.95      0.94       197\n",
            "           8       0.02      0.09      0.03        89\n",
            "           9       0.00      0.00      0.00         1\n",
            "          10       0.12      0.21      0.15       214\n",
            "          11       0.03      0.07      0.04       151\n",
            "          12       0.99      1.00      0.99       218\n",
            "          13       0.98      1.00      0.99    100071\n",
            "          14       0.69      0.98      0.81        94\n",
            "          15       0.06      0.34      0.10        44\n",
            "          16       0.84      0.97      0.90      5982\n",
            "          17       0.03      0.88      0.05        51\n",
            "          18       0.07      0.71      0.12        63\n",
            "          19       0.99      0.98      0.99      2414\n",
            "          20       0.80      0.73      0.76        22\n",
            "          21       0.05      0.86      0.09        29\n",
            "          22       0.98      0.90      0.94    122443\n",
            "          23       0.03      0.04      0.03       241\n",
            "          25       0.06      0.18      0.09       190\n",
            "          27       0.66      0.21      0.32      1699\n",
            "          28       0.80      0.84      0.82      2067\n",
            "          29       0.60      0.16      0.25       540\n",
            "          30       0.41      0.22      0.29      1643\n",
            "          31       0.41      0.72      0.53      1096\n",
            "          32       0.01      0.03      0.01        69\n",
            "          33       0.29      0.18      0.22        11\n",
            "          34       0.24      0.31      0.27        32\n",
            "          35       0.00      0.00      0.00        17\n",
            "          36       0.78      0.56      0.65      8834\n",
            "          37       0.03      0.04      0.03       150\n",
            "          38       0.01      0.03      0.01        35\n",
            "          39       0.68      0.86      0.76       375\n",
            "          40       0.47      0.17      0.25      3958\n",
            "          41       0.70      0.26      0.38      2197\n",
            "          42       1.00      0.99      0.99     36002\n",
            "          43       0.07      0.88      0.13       484\n",
            "          44       0.83      0.77      0.80      1222\n",
            "          45       0.67      0.53      0.59      5691\n",
            "          46       0.09      0.19      0.12       473\n",
            "          47       0.88      0.98      0.93       826\n",
            "          48       0.02      0.05      0.02        39\n",
            "          49       0.96      0.96      0.96     18732\n",
            "          50       0.09      0.17      0.12         6\n",
            "          51       0.06      1.00      0.11         6\n",
            "          52       0.88      0.96      0.92       109\n",
            "          53       0.02      0.06      0.03       165\n",
            "          54       0.03      0.27      0.05        15\n",
            "          55       0.40      0.93      0.56      1930\n",
            "\n",
            "    accuracy                           0.92    415327\n",
            "   macro avg       0.42      0.53      0.41    415327\n",
            "weighted avg       0.94      0.92      0.92    415327\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import plot_confusion_matrix,accuracy_score,classification_report\n",
        "ensemblepred = grid.predict(X_test)\n",
        "print(classification_report(y_test,ensemblepred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H05YYocoDlXB"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pprd = grid.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB4lrfKVDlXC",
        "outputId": "f2003961-859b-4d14-c31b-4654fa5a2f08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9755783236696552\n"
          ]
        }
      ],
      "source": [
        "#roc auc score\n",
        "auc = metrics.roc_auc_score(y_test, pprd, multi_class='ovo', average='weighted')\n",
        "print(auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6ZblPa88rTy"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "# save the model to disk\n",
        "filename = '/content/drive/My Drive/Colab Notebooks/MVTmodel_tn_sm.sav'\n",
        "pickle.dump(VTensemble, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEM6eGcF2JRl"
      },
      "source": [
        "### tuning xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vyr9n2fu2aqp"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.experimental import enable_halving_search_cv  \n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "\n",
        "xgb_classifier = XGBClassifier()\n",
        "xgbparams = {'max_depth': [5,10,20,50]}\n",
        "\n",
        "xgbgrid = HalvingGridSearchCV(xgb_classifier, xgbparams, scoring='accuracy', n_jobs=-1).fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXy6-Ws-hkQm"
      },
      "outputs": [],
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (xgbgrid.best_score_, clf.best_params_))\n",
        "means = xgbgrid.cv_results_['mean_test_score']\n",
        "stds = xgbgrid.cv_results_['std_test_score']\n",
        "params = xgbgrid.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ySLFEkR2spD"
      },
      "outputs": [],
      "source": [
        "XGBpred = xgbgrid.predict(X_test)\n",
        "print(classification_report(y_test,XGBpred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrzbRdzml9OU"
      },
      "source": [
        "### tuning AB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQ5LFRWHmApE"
      },
      "outputs": [],
      "source": [
        "from sklearn.experimental import enable_halving_search_cv  \n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "clf = AdaBoostClassifier(DecisionTreeClassifier())\n",
        "abparam = {'n_estimators': [50,100]                                                                                                               \n",
        "           }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqUQ74ArrURw"
      },
      "outputs": [],
      "source": [
        "abclf = HalvingGridSearchCV(clf, abparam, scoring='accuracy').fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g67oMEbJGOV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6565063e-477b-4911-fee0-4eacfd773892"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.978272 using {'n_estimators': 100}\n",
            "0.977396 (0.001989) with: {'n_estimators': 50}\n",
            "0.978272 (0.001945) with: {'n_estimators': 100}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (abclf.best_score_, abclf.best_params_))\n",
        "means = abclf.cv_results_['mean_test_score']\n",
        "stds = abclf.cv_results_['std_test_score']\n",
        "params = abclf.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXoXeH05Dv5y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42e080e2-3e74-4033-ceb2-fbd9d24d4695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.60      0.75        10\n",
            "           1       1.00      1.00      1.00         5\n",
            "           2       0.76      1.00      0.86        28\n",
            "           3       0.98      0.99      0.99     94137\n",
            "           4       0.14      0.00      0.01       210\n",
            "           7       0.93      0.98      0.96       197\n",
            "           8       0.04      0.02      0.03        89\n",
            "           9       0.00      0.00      0.00         1\n",
            "          10       0.35      0.10      0.16       214\n",
            "          11       0.07      0.02      0.03       151\n",
            "          12       1.00      1.00      1.00       218\n",
            "          13       1.00      1.00      1.00    100071\n",
            "          14       0.90      0.95      0.92        94\n",
            "          15       0.43      0.14      0.21        44\n",
            "          16       0.90      0.96      0.92      5982\n",
            "          17       0.00      0.00      0.00        51\n",
            "          18       0.09      0.03      0.05        63\n",
            "          19       1.00      0.99      1.00      2414\n",
            "          20       0.93      0.59      0.72        22\n",
            "          21       0.91      0.34      0.50        29\n",
            "          22       0.97      0.97      0.97    122443\n",
            "          23       0.09      0.02      0.03       241\n",
            "          25       0.28      0.04      0.07       190\n",
            "          27       0.66      0.67      0.67      1699\n",
            "          28       0.83      0.90      0.87      2067\n",
            "          29       0.56      0.51      0.53       540\n",
            "          30       0.60      0.37      0.46      1643\n",
            "          31       0.84      0.74      0.79      1096\n",
            "          32       0.03      0.01      0.02        69\n",
            "          33       0.75      0.27      0.40        11\n",
            "          34       0.60      0.28      0.38        32\n",
            "          35       0.00      0.00      0.00        17\n",
            "          36       0.76      0.82      0.79      8834\n",
            "          37       0.05      0.02      0.03       150\n",
            "          38       0.00      0.00      0.00        35\n",
            "          39       0.73      0.78      0.76       375\n",
            "          40       0.54      0.47      0.51      3958\n",
            "          41       0.77      0.86      0.81      2197\n",
            "          42       0.99      0.99      0.99     36002\n",
            "          43       0.65      0.55      0.60       484\n",
            "          44       0.89      0.82      0.85      1222\n",
            "          45       0.78      0.85      0.81      5691\n",
            "          46       0.36      0.15      0.21       473\n",
            "          47       0.97      0.98      0.97       826\n",
            "          48       0.14      0.03      0.04        39\n",
            "          49       0.96      0.99      0.97     18732\n",
            "          50       0.60      0.50      0.55         6\n",
            "          51       1.00      1.00      1.00         6\n",
            "          52       0.95      0.97      0.96       109\n",
            "          53       0.03      0.01      0.02       165\n",
            "          54       0.20      0.07      0.10        15\n",
            "          55       0.56      0.70      0.62      1930\n",
            "\n",
            "    accuracy                           0.96    415327\n",
            "   macro avg       0.59      0.52      0.54    415327\n",
            "weighted avg       0.96      0.96      0.96    415327\n",
            "\n"
          ]
        }
      ],
      "source": [
        " from sklearn.metrics import plot_confusion_matrix,accuracy_score,classification_report\n",
        " y_true, y_pred = y_test, abclf.predict(X_test)\n",
        " print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btWJj8ILDnaD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c5f6759-8df4-45f5-84b5-cfb76d864204"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on the train set:  0.9995497459765486\n",
            "accuracy on the test set:  0.9603998776867384\n"
          ]
        }
      ],
      "source": [
        "print('accuracy on the train set: ', accuracy_score(abclf.predict(X_train), y_train))\n",
        "print('accuracy on the test set: ', accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDi5f6dkDnaE"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pprd = abclf.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axUtBo9iDnaE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92f5eeb4-bebd-40b1-cc66-7c07c829fd14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9756874916485627\n"
          ]
        }
      ],
      "source": [
        "auc = metrics.roc_auc_score(y_test, pprd, multi_class='ovo', average='weighted')\n",
        "print(auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CaGL4JhDnaF"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "# save the model to disk\n",
        "filename = '/content/drive/My Drive/Colab Notebooks/MCL_ABmodel_m_TN.sav'\n",
        "pickle.dump(abclf, open(filename, 'wb'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "GYzKS9B019vf",
        "3ciAuVvNeYL5",
        "sismJcs3JFlN"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}